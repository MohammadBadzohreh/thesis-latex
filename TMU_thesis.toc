\contentsline {chapter}{فهرست جداول}{ه}{chapter*.2}%
\contentsline {chapter}{فهرست تصاویر}{و}{chapter*.3}%
\contentsline {chapter}{پیش‌گفتار}{1}{section*.5}%
\contentsline {chapter}{\numberline {1}مفاهیم اولیه}{2}{chapter.1}%
\contentsline {section}{\numberline {1.1}مقدمه}{2}{section.1.1}%
\contentsline {subsection}{\numberline {1.1.1}آغاز هوش مصنوعی و هدف اصلی}{2}{subsection.1.1.1}%
\contentsline {subsection}{\numberline {1.1.2}دورهٔ طلایی و پیشرفت‌های اولیه}{3}{subsection.1.1.2}%
\contentsline {subsection}{\numberline {1.1.3}انتظارات بیش از حد و ظهور عصر تاریک}{3}{subsection.1.1.3}%
\contentsline {subsection}{\numberline {1.1.4}عوامل اصلی عصر تاریک هوش مصنوعی}{3}{subsection.1.1.4}%
\contentsline {subsection}{\numberline {1.1.5}پایان عصر تاریک و بازگشت هوش مصنوعی}{4}{subsection.1.1.5}%
\contentsline {section}{\numberline {1.2}انواع مدل یادگیری ماشین و شبکه های عصبی}{5}{section.1.2}%
\contentsline {subsection}{\numberline {1.2.1}یادگیری ماشین: مروری کلی}{5}{subsection.1.2.1}%
\contentsline {subsection}{\numberline {1.2.2}تقسیم‌بندی‌های اصلی در یادگیری ماشین}{5}{subsection.1.2.2}%
\contentsline {subsection}{\numberline {1.2.3}یادگیری نظارت شده (Supervised-Learning)}{5}{subsection.1.2.3}%
\contentsline {subsubsection}{طبقه‌بندی (Classification)}{6}{section*.6}%
\contentsline {subsubsection}{رگرسیون (regression)}{6}{section*.7}%
\contentsline {subsubsection}{یادگیری تقویتی (Reinforcement-Learning)}{6}{section*.8}%
\contentsline {subsection}{\numberline {1.2.4}معرفی چند مدل از الگوریتم یادگیری کلاسیک }{7}{subsection.1.2.4}%
\contentsline {subsubsection}{نزدیک ترین همسایه(k-nearest-Neighbors)}{7}{section*.9}%
\contentsline {subsubsection}{مزایا:}{7}{section*.10}%
\contentsline {subsubsection}{معایب:}{7}{section*.11}%
\contentsline {subsection}{\numberline {1.2.5}ماشین بردار پشتیبان:(Support-Vector-Machine)}{8}{subsection.1.2.5}%
\contentsline {subsubsection}{مزایا:}{8}{section*.12}%
\contentsline {subsubsection}{معایب:}{8}{section*.13}%
\contentsline {subsection}{\numberline {1.2.6} بیز ساده (Naive-Bayes):}{8}{subsection.1.2.6}%
\contentsline {subsubsection}{مزایا:}{9}{section*.14}%
\contentsline {subsection}{\numberline {1.2.7}معایب:}{9}{subsection.1.2.7}%
\contentsline {subsection}{\numberline {1.2.8}شبکه‌های عصبی بازگشتی (RNN) و شبکه‌های حافظه بلند مدت کوتاه‌مدت (LSTM)}{9}{subsection.1.2.8}%
\contentsline {subsection}{\numberline {1.2.9}RNN:}{10}{subsection.1.2.9}%
\contentsline {subsubsection}{ساختار و عملکرد RNN:}{10}{section*.15}%
\contentsline {subsection}{\numberline {1.2.10}مزایا و معایب Rnn:}{10}{subsection.1.2.10}%
\contentsline {subsubsection}{مزایا:}{11}{section*.16}%
\contentsline {subsubsection}{معایب:}{11}{section*.17}%
\contentsline {subsection}{\numberline {1.2.11}شبکه‌های حافظه بلندمدت-کوتاه‌مدت (LSTM):}{11}{subsection.1.2.11}%
\contentsline {subsubsection}{علل پیدایش lstm:}{11}{section*.18}%
\contentsline {subsubsection}{ Gradient Vanishing:}{12}{section*.19}%
\contentsline {subsection}{\numberline {1.2.12}ظهور Lstm:}{12}{subsection.1.2.12}%
\contentsline {subsubsection}{راه‌حل LSTM برای پایداری جریان گرادیان‌ها:}{13}{section*.20}%
\contentsline {section}{\numberline {1.3}اختار LSTM: نوآوری در مقایسه با RNN}{13}{section.1.3}%
\contentsline {subsection}{\numberline {1.3.1}وضعیت سلولی (Cell State):}{13}{subsection.1.3.1}%
\contentsline {subsection}{\numberline {1.3.2}دروازه‌ها (Gates):}{13}{subsection.1.3.2}%
\contentsline {subsection}{\numberline {1.3.3}به‌روزرسانی وضعیت سلولی:}{14}{subsection.1.3.3}%
\contentsline {subsubsection}{علت پایداری گرادیان در Lstm:}{15}{section*.21}%
\contentsline {subsection}{\numberline {1.3.4}مشکلات کلی rnn و lstm و ظهور ترانسفومرها}{15}{subsection.1.3.4}%
\contentsline {subsubsection}{ مشکل وابستگی ترتیبی در RNNها و LSTMها}{15}{section*.22}%
\contentsline {subsubsection}{ محدودیت در یادگیری وابستگی‌های بسیار طولانی}{16}{section*.23}%
\contentsline {subsubsection}{پیچیدگی محاسباتی و حافظه}{16}{section*.24}%
\contentsline {subsubsection}{مشکل پردازش وابستگی‌های غیرمتوالی}{17}{section*.25}%
\contentsline {subsubsection}{گرادیان‌های ناپایدار و مشکلات بهینه‌سازی:}{17}{section*.26}%
\contentsline {subsubsection}{نیاز به مدلی با ظرفیت بیشتر و سرعت بالاتر:}{17}{section*.27}%
\contentsline {chapter}{\numberline {2}پیشینه پژوهش}{20}{chapter.2}%
\contentsline {section}{\numberline {2.1}مقدمه}{20}{section.2.1}%
\contentsline {section}{\numberline {2.2}مشکلات ترجمه ماشینی و ترانسفورمرها:}{20}{section.2.2}%
\contentsline {section}{\numberline {2.3}ظهور ترانسفورمر ها:}{21}{section.2.3}%
\contentsline {section}{\numberline {2.4}معماری ترانسفورمر ها:}{21}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}Embedding:}{22}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2}positional embedding:}{23}{subsection.2.4.2}%
\contentsline {subsection}{\numberline {2.4.3}attention:}{25}{subsection.2.4.3}%
\contentsline {subsection}{\numberline {2.4.4}Residual Connection (Add):}{29}{subsection.2.4.4}%
\contentsline {subsection}{\numberline {2.4.5}مزایای Residual Connection در ترانسفورمر}{29}{subsection.2.4.5}%
\contentsline {section}{\numberline {2.5}Layer Normalization (Norm):}{30}{section.2.5}%
\contentsline {section}{\numberline {2.6}decoder:}{33}{section.2.6}%
\contentsline {section}{\numberline {2.7}masked multi head attention}{33}{section.2.7}%
\contentsline {section}{\numberline {2.8}مثال عددی mask attention:}{34}{section.2.8}%
\contentsline {section}{\numberline {2.9}vision transformer:}{35}{section.2.9}%
\contentsline {subsection}{\numberline {2.9.1}patch embedding in vision transformer:}{36}{subsection.2.9.1}%
\contentsline {subsection}{\numberline {2.9.2}شکل پچ ها:}{36}{subsection.2.9.2}%
\contentsline {subsection}{\numberline {2.9.3}تعداد پچ ها:}{38}{subsection.2.9.3}%
\contentsline {subsection}{\numberline {2.9.4}بردار کردن هر پچ}{39}{subsection.2.9.4}%
\contentsline {section}{\numberline {2.10}اعمال لایهٔ خطی (Projection):}{39}{section.2.10}%
\contentsline {subsection}{\numberline {2.10.1}CLS Token:}{41}{subsection.2.10.1}%
\contentsline {subsection}{\numberline {2.10.2}vision transformer encoder:}{42}{subsection.2.10.2}%
\contentsline {section}{\numberline {2.11}Swin Transformer:}{43}{section.2.11}%
\contentsline {subsection}{\numberline {2.11.1} قطعه‌بندی پچ (Patch Partition):}{45}{subsection.2.11.1}%
\contentsline {subsection}{\numberline {2.11.2}Linear Embedding:}{45}{subsection.2.11.2}%
\contentsline {subsection}{\numberline {2.11.3}Window Multi-Head Self-Attention:}{46}{subsection.2.11.3}%
\contentsline {subsubsection}{ تعریف پنجره‌های محلی:}{46}{section*.36}%
\contentsline {subsection}{\numberline {2.11.4}Attention:}{47}{subsection.2.11.4}%
\contentsline {subsection}{\numberline {2.11.5}shifted Windows:}{48}{subsection.2.11.5}%
\contentsline {subsubsection}{بلوک اول (W-MSA):}{49}{section*.37}%
\contentsline {subsubsection}{بلوک دوم (SW-MSA):}{49}{section*.38}%
\contentsline {subsection}{\numberline {2.11.6}Mlp:}{51}{subsection.2.11.6}%
\contentsline {subsection}{\numberline {2.11.7}patch merging:}{52}{subsection.2.11.7}%
\contentsline {subsubsection}{1. انتخاب بلوک‌های \((2 \times 2)\)}{52}{section*.39}%
\contentsline {subsubsection}{2. ادغام (Concat) ویژگی‌های چهار پیکسل}{53}{section*.40}%
\contentsline {subsubsection}{3. لایهٔ خطی برای تغییر بعد}{53}{section*.41}%
\contentsline {subsubsection}{4. کاهش ابعاد مکانی}{53}{section*.42}%
\contentsline {chapter}{\numberline {3}روش های پیشنهادی}{55}{chapter.3}%
\contentsline {chapter}{\numberline {4}آزمایشات و نتایج}{56}{chapter.4}%
\contentsline {chapter}{کتاب‌نامه}{57}{chapter*.43}%
\contentsline {chapter}{\numberline {آ}جزئیات مدل‌ها و جدول پارامترها}{58}{appendix.Alph1}%
