\contentsline {chapter}{فهرست جداول}{ه}{chapter*.2}%
\contentsline {chapter}{فهرست تصاویر}{و}{chapter*.3}%
\contentsline {chapter}{پیش‌گفتار}{1}{section*.5}%
\contentsline {chapter}{\numberline {1}مفاهیم اولیه}{2}{chapter.1}%
\contentsline {section}{\numberline {1.1}مقدمه}{2}{section.1.1}%
\contentsline {chapter}{\numberline {2}مفاهیم اولیه}{3}{chapter.2}%
\contentsline {section}{\numberline {2.1}مقدمه}{3}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}آغاز هوش مصنوعی و هدف اصلی}{3}{subsection.2.1.1}%
\contentsline {subsection}{\numberline {2.1.2}دورهٔ طلایی و پیشرفت‌های اولیه}{4}{subsection.2.1.2}%
\contentsline {subsection}{\numberline {2.1.3}انتظارات بیش از حد و ظهور عصر تاریک}{4}{subsection.2.1.3}%
\contentsline {subsection}{\numberline {2.1.4}عوامل اصلی عصر تاریک هوش مصنوعی}{4}{subsection.2.1.4}%
\contentsline {subsection}{\numberline {2.1.5}پایان عصر تاریک و بازگشت هوش مصنوعی}{5}{subsection.2.1.5}%
\contentsline {section}{\numberline {2.2}انواع مدل یادگیری ماشین و شبکه‌های عصبی}{6}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}یادگیری ماشین: مروری کلی}{6}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}تقسیم‌بندی‌های اصلی در یادگیری ماشین}{6}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}یادگیری نظارت‌شده (\lr {Supervised Learning})}{7}{subsection.2.2.3}%
\contentsline {subsubsection}{طبقه‌بندی (\lr {Classification})}{7}{section*.6}%
\contentsline {subsubsection}{رگرسیون (\lr {Regression})}{7}{section*.7}%
\contentsline {subsection}{\numberline {2.2.4}یادگیری تقویتی (\lr {Reinforcement Learning})}{8}{subsection.2.2.4}%
\contentsline {subsection}{\numberline {2.2.5}معرفی چند مدل از الگوریتم یادگیری کلاسیک}{8}{subsection.2.2.5}%
\contentsline {subsubsection}{نزدیک‌ترین همسایه (\lr {k-Nearest Neighbors, kNN})}{8}{section*.8}%
\contentsline {subsubsection}{مزایا:}{8}{section*.9}%
\contentsline {subsubsection}{معایب:}{9}{section*.10}%
\contentsline {subsection}{\numberline {2.2.6}ماشین بردار پشتیبان (\lr {Support Vector Machine, SVM})}{9}{subsection.2.2.6}%
\contentsline {subsubsection}{مزایا:}{9}{section*.11}%
\contentsline {subsubsection}{معایب:}{9}{section*.12}%
\contentsline {subsection}{\numberline {2.2.7}بیز ساده (\lr {Naive Bayes})}{10}{subsection.2.2.7}%
\contentsline {subsubsection}{مزایا:}{10}{section*.13}%
\contentsline {subsubsection}{معایب:}{10}{section*.14}%
\contentsline {subsection}{\numberline {2.2.8}شبکه‌های عصبی بازگشتی (\lr {RNN}) و شبکه‌های حافظه بلندمدت کوتاه‌مدت (\lr {LSTM})}{11}{subsection.2.2.8}%
\contentsline {subsection}{\numberline {2.2.9}\lr {RNN}}{11}{subsection.2.2.9}%
\contentsline {subsubsection}{ساختار و عملکرد \lr {RNN}}{11}{section*.15}%
\contentsline {subsection}{\numberline {2.2.10}مزایا و معایب \lr {RNN}}{12}{subsection.2.2.10}%
\contentsline {subsubsection}{مزایا:}{12}{section*.16}%
\contentsline {subsubsection}{معایب:}{12}{section*.17}%
\contentsline {subsection}{\numberline {2.2.11}شبکه‌های حافظه بلندمدت-کوتاه‌مدت (\lr {LSTM})}{13}{subsection.2.2.11}%
\contentsline {subsubsection}{علل پیدایش \lr {LSTM}}{13}{section*.18}%
\contentsline {subsubsection}{\lr {Gradient Vanishing}}{13}{section*.19}%
\contentsline {subsection}{\numberline {2.2.12}ظهور \lr {LSTM}}{14}{subsection.2.2.12}%
\contentsline {subsubsection}{راه‌حل \lr {LSTM} برای پایداری جریان گرادیان‌ها}{14}{section*.20}%
\contentsline {section}{\numberline {2.3}اختار \lr {LSTM}: نوآوری در مقایسه با \lr {RNN}}{14}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}وضعیت سلولی (\lr {Cell State})}{15}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}دروازه‌ها (\lr {Gates})}{15}{subsection.2.3.2}%
\contentsline {subsection}{\numberline {2.3.3}به‌روزرسانی وضعیت سلولی}{16}{subsection.2.3.3}%
\contentsline {subsubsection}{علت پایداری گرادیان در \lr {LSTM}}{16}{section*.21}%
\contentsline {subsection}{\numberline {2.3.4}مشکلات کلی \lr {RNN} و \lr {LSTM} و ظهور ترنسفورمرها}{17}{subsection.2.3.4}%
\contentsline {subsubsection}{مشکل وابستگی ترتیبی در \lr {RNN}ها و \lr {LSTM}ها}{17}{section*.22}%
\contentsline {subsubsection}{محدودیت در یادگیری وابستگی‌های بسیار طولانی}{18}{section*.23}%
\contentsline {subsubsection}{پیچیدگی محاسباتی و حافظه}{18}{section*.24}%
\contentsline {subsubsection}{مشکل پردازش وابستگی‌های غیرمتوالی}{18}{section*.25}%
\contentsline {subsubsection}{گرادیان‌های ناپایدار و مشکلات بهینه‌سازی}{19}{section*.26}%
\contentsline {subsubsection}{نیاز به مدلی با ظرفیت بیشتر و سرعت بالاتر}{19}{section*.27}%
\contentsline {chapter}{\numberline {3}پیشینه پژوهش}{20}{chapter.3}%
\contentsline {section}{\numberline {3.1}مقدمه}{20}{section.3.1}%
\contentsline {section}{\numberline {3.2}مشکلات ترجمه ماشینی و ترانسفورمرها:}{20}{section.3.2}%
\contentsline {section}{\numberline {3.3}ظهور ترانسفورمر ها:}{21}{section.3.3}%
\contentsline {section}{\numberline {3.4}معماری ترانسفورمر ها:}{21}{section.3.4}%
\contentsline {subsection}{\numberline {3.4.1}Embedding:}{22}{subsection.3.4.1}%
\contentsline {subsection}{\numberline {3.4.2}positional embedding:}{23}{subsection.3.4.2}%
\contentsline {subsection}{\numberline {3.4.3}attention:}{25}{subsection.3.4.3}%
\contentsline {subsection}{\numberline {3.4.4}Residual Connection (Add):}{29}{subsection.3.4.4}%
\contentsline {subsection}{\numberline {3.4.5}مزایای Residual Connection در ترانسفورمر}{29}{subsection.3.4.5}%
\contentsline {section}{\numberline {3.5}Layer Normalization (Norm):}{30}{section.3.5}%
\contentsline {section}{\numberline {3.6}decoder:}{33}{section.3.6}%
\contentsline {section}{\numberline {3.7}masked multi head attention}{33}{section.3.7}%
\contentsline {section}{\numberline {3.8}مثال عددی mask attention:}{34}{section.3.8}%
\contentsline {section}{\numberline {3.9}vision transformer:}{35}{section.3.9}%
\contentsline {subsection}{\numberline {3.9.1}patch embedding in vision transformer:}{36}{subsection.3.9.1}%
\contentsline {subsection}{\numberline {3.9.2}شکل پچ ها:}{36}{subsection.3.9.2}%
\contentsline {subsection}{\numberline {3.9.3}تعداد پچ ها:}{38}{subsection.3.9.3}%
\contentsline {subsection}{\numberline {3.9.4}بردار کردن هر پچ}{39}{subsection.3.9.4}%
\contentsline {section}{\numberline {3.10}اعمال لایهٔ خطی (Projection):}{39}{section.3.10}%
\contentsline {subsection}{\numberline {3.10.1}CLS Token:}{41}{subsection.3.10.1}%
\contentsline {subsection}{\numberline {3.10.2}vision transformer encoder:}{42}{subsection.3.10.2}%
\contentsline {section}{\numberline {3.11}Swin Transformer:}{43}{section.3.11}%
\contentsline {subsection}{\numberline {3.11.1} قطعه‌بندی پچ (Patch Partition):}{45}{subsection.3.11.1}%
\contentsline {subsection}{\numberline {3.11.2}Linear Embedding:}{45}{subsection.3.11.2}%
\contentsline {subsection}{\numberline {3.11.3}Window Multi-Head Self-Attention:}{46}{subsection.3.11.3}%
\contentsline {subsubsection}{ تعریف پنجره‌های محلی:}{46}{section*.36}%
\contentsline {subsection}{\numberline {3.11.4}Attention:}{47}{subsection.3.11.4}%
\contentsline {subsection}{\numberline {3.11.5}shifted Windows:}{48}{subsection.3.11.5}%
\contentsline {subsubsection}{بلوک اول (W-MSA):}{49}{section*.37}%
\contentsline {subsubsection}{بلوک دوم (SW-MSA):}{49}{section*.38}%
\contentsline {subsection}{\numberline {3.11.6}Mlp:}{51}{subsection.3.11.6}%
\contentsline {subsection}{\numberline {3.11.7}patch merging:}{52}{subsection.3.11.7}%
\contentsline {subsubsection}{1. انتخاب بلوک‌های \((2 \times 2)\)}{52}{section*.39}%
\contentsline {subsubsection}{2. ادغام (Concat) ویژگی‌های چهار پیکسل}{53}{section*.40}%
\contentsline {subsubsection}{3. لایهٔ خطی برای تغییر بعد}{53}{section*.41}%
\contentsline {subsubsection}{4. کاهش ابعاد مکانی}{53}{section*.42}%
\contentsline {chapter}{\numberline {4}روش های پیشنهادی}{56}{chapter.4}%
\contentsline {chapter}{\numberline {5}آزمایشات و نتایج}{57}{chapter.5}%
\contentsline {chapter}{کتاب‌نامه}{58}{chapter*.43}%
\contentsline {chapter}{\numberline {آ}جزئیات مدل‌ها و جدول پارامترها}{61}{appendix.Alph1}%
