\contentsline {chapter}{فهرست جداول}{ه}{chapter*.2}%
\contentsline {chapter}{فهرست تصاویر}{و}{chapter*.3}%
\contentsline {chapter}{پیش‌گفتار}{1}{section*.5}%
\contentsline {chapter}{\numberline {1}مفاهیم اولیه}{2}{chapter.1}%
\contentsline {section}{\numberline {1.1}مقدمه}{2}{section.1.1}%
\contentsline {chapter}{\numberline {2}مفاهیم اولیه}{3}{chapter.2}%
\contentsline {section}{\numberline {2.1}مقدمه}{3}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}آغاز هوش مصنوعی و هدف اصلی}{3}{subsection.2.1.1}%
\contentsline {subsection}{\numberline {2.1.2}دورهٔ طلایی و پیشرفت‌های اولیه}{4}{subsection.2.1.2}%
\contentsline {subsection}{\numberline {2.1.3}انتظارات بیش از حد و ظهور عصر تاریک}{4}{subsection.2.1.3}%
\contentsline {subsection}{\numberline {2.1.4}عوامل اصلی عصر تاریک هوش مصنوعی}{4}{subsection.2.1.4}%
\contentsline {subsection}{\numberline {2.1.5}پایان عصر تاریک و بازگشت هوش مصنوعی}{5}{subsection.2.1.5}%
\contentsline {section}{\numberline {2.2}انواع مدل یادگیری ماشین و شبکه‌های عصبی}{6}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}یادگیری ماشین: مروری کلی}{6}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}تقسیم‌بندی‌های اصلی در یادگیری ماشین}{6}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}یادگیری نظارت‌شده (\lr {Supervised Learning})}{7}{subsection.2.2.3}%
\contentsline {subsubsection}{طبقه‌بندی (\lr {Classification})}{7}{section*.6}%
\contentsline {subsubsection}{رگرسیون (\lr {Regression})}{7}{section*.7}%
\contentsline {subsection}{\numberline {2.2.4}یادگیری تقویتی (\lr {Reinforcement Learning})}{8}{subsection.2.2.4}%
\contentsline {subsection}{\numberline {2.2.5}معرفی چند مدل از الگوریتم یادگیری کلاسیک}{8}{subsection.2.2.5}%
\contentsline {subsubsection}{نزدیک‌ترین همسایه (\lr {k-Nearest Neighbors, kNN})}{8}{section*.8}%
\contentsline {subsubsection}{مزایا:}{8}{section*.9}%
\contentsline {subsubsection}{معایب:}{9}{section*.10}%
\contentsline {subsection}{\numberline {2.2.6}ماشین بردار پشتیبان (\lr {Support Vector Machine, SVM})}{9}{subsection.2.2.6}%
\contentsline {subsubsection}{مزایا:}{9}{section*.11}%
\contentsline {subsubsection}{معایب:}{9}{section*.12}%
\contentsline {subsection}{\numberline {2.2.7}بیز ساده (\lr {Naive Bayes})}{10}{subsection.2.2.7}%
\contentsline {subsubsection}{مزایا:}{10}{section*.13}%
\contentsline {subsubsection}{معایب:}{10}{section*.14}%
\contentsline {subsection}{\numberline {2.2.8}شبکه‌های عصبی بازگشتی (\lr {RNN}) و شبکه‌های حافظه بلندمدت کوتاه‌مدت (\lr {LSTM})}{11}{subsection.2.2.8}%
\contentsline {subsection}{\numberline {2.2.9}\lr {RNN}}{11}{subsection.2.2.9}%
\contentsline {subsubsection}{ساختار و عملکرد \lr {RNN}}{11}{section*.15}%
\contentsline {subsection}{\numberline {2.2.10}مزایا و معایب \lr {RNN}}{12}{subsection.2.2.10}%
\contentsline {subsubsection}{مزایا:}{12}{section*.16}%
\contentsline {subsubsection}{معایب:}{13}{section*.17}%
\contentsline {subsection}{\numberline {2.2.11}شبکه‌های حافظه بلندمدت-کوتاه‌مدت (\lr {LSTM})}{13}{subsection.2.2.11}%
\contentsline {subsubsection}{علل پیدایش \lr {LSTM}}{13}{section*.18}%
\contentsline {subsubsection}{\lr {Gradient Vanishing}}{13}{section*.19}%
\contentsline {subsection}{\numberline {2.2.12}ظهور \lr {LSTM}}{14}{subsection.2.2.12}%
\contentsline {subsubsection}{راه‌حل \lr {LSTM} برای پایداری جریان گرادیان‌ها}{14}{section*.20}%
\contentsline {section}{\numberline {2.3}اختار \lr {LSTM}: نوآوری در مقایسه با \lr {RNN}}{15}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}وضعیت سلولی (\lr {Cell State})}{15}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}دروازه‌ها (\lr {Gates})}{15}{subsection.2.3.2}%
\contentsline {subsection}{\numberline {2.3.3}به‌روزرسانی وضعیت سلولی}{16}{subsection.2.3.3}%
\contentsline {subsubsection}{علت پایداری گرادیان در \lr {LSTM}}{17}{section*.21}%
\contentsline {subsection}{\numberline {2.3.4}مشکلات کلی \lr {RNN} و \lr {LSTM} و ظهور ترنسفورمرها}{17}{subsection.2.3.4}%
\contentsline {subsubsection}{مشکل وابستگی ترتیبی در \lr {RNN}ها و \lr {LSTM}ها}{18}{section*.22}%
\contentsline {subsubsection}{محدودیت در یادگیری وابستگی‌های بسیار طولانی}{18}{section*.23}%
\contentsline {subsubsection}{پیچیدگی محاسباتی و حافظه}{18}{section*.24}%
\contentsline {subsubsection}{مشکل پردازش وابستگی‌های غیرمتوالی}{19}{section*.25}%
\contentsline {subsubsection}{گرادیان‌های ناپایدار و مشکلات بهینه‌سازی}{19}{section*.26}%
\contentsline {subsubsection}{نیاز به مدلی با ظرفیت بیشتر و سرعت بالاتر}{19}{section*.27}%
\contentsline {chapter}{\numberline {3}پیشینه پژوهش}{21}{chapter.3}%
\contentsline {section}{\numberline {3.1}مقدمه}{21}{section.3.1}%
\contentsline {section}{\numberline {3.2}مشکلات ترجمه ماشینی و ترانسفورمرها}{21}{section.3.2}%
\contentsline {section}{\numberline {3.3}ظهور ترانسفورمرها}{22}{section.3.3}%
\contentsline {section}{\numberline {3.4}معماری ترانسفورمرها}{22}{section.3.4}%
\contentsline {subsection}{\numberline {3.4.1}Embedding}{23}{subsection.3.4.1}%
\contentsline {subsection}{\numberline {3.4.2}\lr {positional embedding}}{24}{subsection.3.4.2}%
\contentsline {subsection}{\numberline {3.4.3}\lr {attention}}{26}{subsection.3.4.3}%
\contentsline {subsection}{\numberline {3.4.4}\lr {Residual Connection (Add)}}{30}{subsection.3.4.4}%
\contentsline {subsection}{\numberline {3.4.5}مزایای \lr {Residual Connection} در ترانسفورمر}{30}{subsection.3.4.5}%
\contentsline {section}{\numberline {3.5}Layer Normalization (Norm):}{31}{section.3.5}%
\contentsline {paragraph}{\lr {Residual Connection}:}{33}{section*.36}%
\contentsline {paragraph}{\lr {Layer Normalization}:}{33}{section*.37}%
\contentsline {section}{\numberline {3.6}\lr {decoder}}{34}{section.3.6}%
\contentsline {section}{\numberline {3.7}masked multi head attention}{34}{section.3.7}%
\contentsline {section}{\numberline {3.8}مثال عددی \lr {mask attention}}{35}{section.3.8}%
\contentsline {section}{\numberline {3.9}\lr {vision transformer}}{37}{section.3.9}%
\contentsline {subsection}{\numberline {3.9.1}\lr {patch embedding in vision transformer}}{37}{subsection.3.9.1}%
\contentsline {subsection}{\numberline {3.9.2}شکل پچ‌ها:}{38}{subsection.3.9.2}%
\contentsline {subsection}{\numberline {3.9.3}تعداد پچ‌ها:}{38}{subsection.3.9.3}%
\contentsline {subsection}{\numberline {3.9.4}بردارکردن هر پچ}{40}{subsection.3.9.4}%
\contentsline {section}{\numberline {3.10}اعمال لایهٔ خطی (\lr {Projection})}{41}{section.3.10}%
\contentsline {subsection}{\numberline {3.10.1}\lr {CLS Token}}{42}{subsection.3.10.1}%
\contentsline {subsection}{\numberline {3.10.2}\lr {Encoder in vision transformer}}{43}{subsection.3.10.2}%
\contentsline {section}{\numberline {3.11}Swin Transformer:}{44}{section.3.11}%
\contentsline {subsection}{\numberline {3.11.1}قطعه‌بندی پچ (\lr {Patch Partition})}{45}{subsection.3.11.1}%
\contentsline {subsection}{\numberline {3.11.2}\lr {Linear Embedding}}{46}{subsection.3.11.2}%
\contentsline {subsection}{\numberline {3.11.3}\lr {Window Multi-Head Self-Attention}}{47}{subsection.3.11.3}%
\contentsline {subsubsection}{تعریف پنجره‌های محلی}{47}{section*.38}%
\contentsline {subsection}{\numberline {3.11.4}\lr {Attention}}{48}{subsection.3.11.4}%
\contentsline {subsection}{\numberline {3.11.5}\lr {shifted Windows}}{49}{subsection.3.11.5}%
\contentsline {subsubsection}{بلوک اول (\lr {\lr {W-MSA}}):}{50}{section*.39}%
\contentsline {subsubsection}{بلوک دوم (\lr {\lr {SW-MSA}}):}{50}{section*.40}%
\contentsline {subsection}{\numberline {3.11.6}Mlp}{51}{subsection.3.11.6}%
\contentsline {subsection}{\numberline {3.11.7}\lr {patch merging}}{52}{subsection.3.11.7}%
\contentsline {subsubsection}{1. انتخاب بلوک‌های \((2 \times 2)\)}{53}{section*.41}%
\contentsline {subsubsection}{2. ادغام (Concat) ویژگی‌های چهار پیکسل}{53}{section*.42}%
\contentsline {subsubsection}{3. لایهٔ خطی برای تغییر بعد}{53}{section*.43}%
\contentsline {subsubsection}{4. کاهش ابعاد مکانی}{53}{section*.44}%
\contentsline {chapter}{\numberline {4}پیشینه پژوهش}{56}{chapter.4}%
\contentsline {subsection}{\numberline {4.0.1}ویژگی‌های محلی (\lr {Local Features})}{57}{subsection.4.0.1}%
\contentsline {subsection}{\numberline {4.0.2}ویژگی‌های جهانی (\lr {Global Features})}{57}{subsection.4.0.2}%
\contentsline {subsection}{\numberline {4.0.3}ترانسفورمرها و محدودیت‌های دید محلی}{58}{subsection.4.0.3}%
\contentsline {subsection}{\numberline {4.0.4}روش اول:}{58}{subsection.4.0.4}%
\contentsline {subsection}{\numberline {4.0.5}تبدیل تصاویر به دو پچ مجزا:}{58}{subsection.4.0.5}%
\contentsline {subsection}{\numberline {4.0.6}هماهنگ سازی پچ ها:}{59}{subsection.4.0.6}%
\contentsline {subsection}{\numberline {4.0.7}\lr {Positional Embedding}}{63}{subsection.4.0.7}%
\contentsline {subsection}{\numberline {4.0.8}لایه های اول تا هشتم انکودر}{64}{subsection.4.0.8}%
\contentsline {subsection}{\numberline {4.0.9}لایه نهم انکودر}{64}{subsection.4.0.9}%
\contentsline {subsection}{\numberline {4.0.10}محاسبهٔ ماتریس شباهت (\(QK^T\)) و میانگین‌گیری}{65}{subsection.4.0.10}%
\contentsline {subsection}{\numberline {4.0.11}اعمال مقیاس‌بندی \( \frac {1}{\sqrt {d_k}} \) و \textit {Softmax}}{66}{subsection.4.0.11}%
\contentsline {subsection}{\numberline {4.0.12}ادغام وزنی}{68}{subsection.4.0.12}%
\contentsline {section}{\numberline {4.1}روش دوم:}{68}{section.4.1}%
\contentsline {chapter}{\numberline {5}آزمایشات و نتایج}{69}{chapter.5}%
\contentsline {chapter}{کتاب‌نامه}{70}{chapter*.57}%
\contentsline {chapter}{\numberline {آ}جزئیات مدل‌ها و جدول پارامترها}{75}{appendix.Alph1}%
