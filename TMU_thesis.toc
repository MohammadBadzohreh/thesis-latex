\contentsline {chapter}{فهرست جداول}{ه}{chapter*.2}%
\contentsline {chapter}{فهرست تصاویر}{و}{chapter*.3}%
\contentsline {chapter}{پیش‌گفتار}{1}{section*.5}%
\contentsline {chapter}{\numberline {1}مفاهیم اولیه}{2}{chapter.1}%
\contentsline {section}{\numberline {1.1}مقدمه}{2}{section.1.1}%
\contentsline {chapter}{\numberline {2}مفاهیم اولیه}{3}{chapter.2}%
\contentsline {section}{\numberline {2.1}مقدمه}{3}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}آغاز هوش مصنوعی و هدف اصلی}{3}{subsection.2.1.1}%
\contentsline {subsection}{\numberline {2.1.2}دورهٔ طلایی و پیشرفت‌های اولیه}{4}{subsection.2.1.2}%
\contentsline {subsection}{\numberline {2.1.3}انتظارات بیش از حد و ظهور عصر تاریک}{4}{subsection.2.1.3}%
\contentsline {subsection}{\numberline {2.1.4}عوامل اصلی عصر تاریک هوش مصنوعی}{5}{subsection.2.1.4}%
\contentsline {subsection}{\numberline {2.1.5}پایان عصر تاریک و بازگشت هوش مصنوعی}{5}{subsection.2.1.5}%
\contentsline {section}{\numberline {2.2}انواع مدل یادگیری ماشین و شبکه‌های عصبی}{6}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}یادگیری ماشین: مروری کلی}{6}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}تقسیم‌بندی‌های اصلی در یادگیری ماشین}{7}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}یادگیری نظارت‌شده}{7}{subsection.2.2.3}%
\contentsline {subsubsection}{طبقه‌بندی}{7}{section*.6}%
\contentsline {subsubsection}{رگرسیون}{8}{section*.7}%
\contentsline {subsection}{\numberline {2.2.4}یادگیری تقویتی}{8}{subsection.2.2.4}%
\contentsline {subsection}{\numberline {2.2.5}معرفی چند مدل از الگوریتم یادگیری کلاسیک}{9}{subsection.2.2.5}%
\contentsline {subsubsection}{نزدیک‌ترین همسایه }{9}{section*.8}%
\contentsline {subsubsection}{مزایا:}{9}{section*.9}%
\contentsline {subsubsection}{معایب:}{9}{section*.10}%
\contentsline {subsection}{\numberline {2.2.6}ماشین بردار پشتیبان}{10}{subsection.2.2.6}%
\contentsline {subsubsection}{مزایا:}{10}{section*.11}%
\contentsline {subsubsection}{معایب:}{10}{section*.12}%
\contentsline {subsection}{\numberline {2.2.7}بیز ساده}{11}{subsection.2.2.7}%
\contentsline {subsubsection}{مزایا:}{11}{section*.13}%
\contentsline {subsubsection}{معایب:}{11}{section*.14}%
\contentsline {subsection}{\numberline {2.2.8}شبکه‌های عصبی بازگشتی و شبکه‌های حافظه بلندمدت کوتاه‌مدت}{12}{subsection.2.2.8}%
\contentsline {subsection}{\numberline {2.2.9}شبکه‌های عصبی بازگشتی}{12}{subsection.2.2.9}%
\contentsline {subsubsection}{ساختار و عملکرد شبکه‌های عصبی بازگشتی}{13}{section*.15}%
\contentsline {subsection}{\numberline {2.2.10}مزایا و معایب شبکه‌های عصبی بازگشتی}{13}{subsection.2.2.10}%
\contentsline {subsubsection}{مزایا:}{13}{section*.16}%
\contentsline {subsubsection}{معایب:}{14}{section*.17}%
\contentsline {subsection}{\numberline {2.2.11}شبکه‌های حافظه بلندمدت-کوتاه‌مدت}{14}{subsection.2.2.11}%
\contentsline {subsubsection}{علل پیدایش \lr {LSTM}}{14}{section*.18}%
\contentsline {subsubsection}{\lr {Gradient Vanishing}}{14}{section*.19}%
\contentsline {subsection}{\numberline {2.2.12}ظهور \lr {LSTM}}{15}{subsection.2.2.12}%
\contentsline {subsubsection}{راه‌حل \lr {LSTM} برای پایداری جریان گرادیان‌ها}{16}{section*.20}%
\contentsline {section}{\numberline {2.3}اختار \lr {LSTM}: نوآوری در مقایسه با \lr {RNN}}{16}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}وضعیت سلولی (\lr {Cell State})}{16}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}دروازه‌ها (\lr {Gates})}{16}{subsection.2.3.2}%
\contentsline {subsection}{\numberline {2.3.3}به‌روزرسانی وضعیت سلولی}{18}{subsection.2.3.3}%
\contentsline {subsubsection}{علت پایداری گرادیان در \lr {LSTM}}{18}{section*.21}%
\contentsline {subsection}{\numberline {2.3.4}مشکلات کلی \lr {RNN} و \lr {LSTM} و ظهور ترنسفورمرها}{19}{subsection.2.3.4}%
\contentsline {subsubsection}{مشکل وابستگی ترتیبی در \lr {RNN}ها و \lr {LSTM}ها}{19}{section*.22}%
\contentsline {subsubsection}{محدودیت در یادگیری وابستگی‌های بسیار طولانی}{19}{section*.23}%
\contentsline {subsubsection}{پیچیدگی محاسباتی و حافظه}{20}{section*.24}%
\contentsline {subsubsection}{مشکل پردازش وابستگی‌های غیرمتوالی}{20}{section*.25}%
\contentsline {subsubsection}{گرادیان‌های ناپایدار و مشکلات بهینه‌سازی}{20}{section*.26}%
\contentsline {subsubsection}{نیاز به مدلی با ظرفیت بیشتر و سرعت بالاتر}{21}{section*.27}%
\contentsline {chapter}{\numberline {3}پیشینه پژوهش}{22}{chapter.3}%
\contentsline {section}{\numberline {3.1}مقدمه}{22}{section.3.1}%
\contentsline {section}{\numberline {3.2}مشکلات ترجمه ماشینی و ترانسفورمرها}{22}{section.3.2}%
\contentsline {section}{\numberline {3.3}ظهور ترانسفورمرها}{23}{section.3.3}%
\contentsline {section}{\numberline {3.4}معماری ترانسفورمرها}{23}{section.3.4}%
\contentsline {subsection}{\numberline {3.4.1}Embedding}{24}{subsection.3.4.1}%
\contentsline {subsection}{\numberline {3.4.2}\lr {positional embedding}}{25}{subsection.3.4.2}%
\contentsline {subsection}{\numberline {3.4.3}\lr {attention}}{27}{subsection.3.4.3}%
\contentsline {subsection}{\numberline {3.4.4}\lr {Residual Connection (Add)}}{31}{subsection.3.4.4}%
\contentsline {subsection}{\numberline {3.4.5}مزایای \lr {Residual Connection} در ترانسفورمر}{31}{subsection.3.4.5}%
\contentsline {section}{\numberline {3.5}Layer Normalization (Norm):}{32}{section.3.5}%
\contentsline {paragraph}{\lr {Residual Connection}:}{34}{section*.36}%
\contentsline {paragraph}{\lr {Layer Normalization}:}{34}{section*.37}%
\contentsline {section}{\numberline {3.6}\lr {decoder}}{35}{section.3.6}%
\contentsline {section}{\numberline {3.7}masked multi head attention}{35}{section.3.7}%
\contentsline {section}{\numberline {3.8}مثال عددی \lr {mask attention}}{36}{section.3.8}%
\contentsline {section}{\numberline {3.9}\lr {vision transformer}}{38}{section.3.9}%
\contentsline {subsection}{\numberline {3.9.1}\lr {patch embedding in vision transformer}}{38}{subsection.3.9.1}%
\contentsline {subsection}{\numberline {3.9.2}شکل پچ‌ها:}{39}{subsection.3.9.2}%
\contentsline {subsection}{\numberline {3.9.3}تعداد پچ‌ها:}{39}{subsection.3.9.3}%
\contentsline {subsection}{\numberline {3.9.4}بردارکردن هر پچ}{41}{subsection.3.9.4}%
\contentsline {section}{\numberline {3.10}اعمال لایهٔ خطی (\lr {Projection})}{42}{section.3.10}%
\contentsline {subsection}{\numberline {3.10.1}\lr {CLS Token}}{43}{subsection.3.10.1}%
\contentsline {subsection}{\numberline {3.10.2}\lr {Encoder in vision transformer}}{44}{subsection.3.10.2}%
\contentsline {section}{\numberline {3.11}Swin Transformer:}{45}{section.3.11}%
\contentsline {subsection}{\numberline {3.11.1}قطعه‌بندی پچ (\lr {Patch Partition})}{46}{subsection.3.11.1}%
\contentsline {subsection}{\numberline {3.11.2}\lr {Linear Embedding}}{47}{subsection.3.11.2}%
\contentsline {subsection}{\numberline {3.11.3}\lr {Window Multi-Head Self-Attention}}{48}{subsection.3.11.3}%
\contentsline {subsubsection}{تعریف پنجره‌های محلی}{48}{section*.38}%
\contentsline {subsection}{\numberline {3.11.4}\lr {Attention}}{49}{subsection.3.11.4}%
\contentsline {subsection}{\numberline {3.11.5}\lr {shifted Windows}}{50}{subsection.3.11.5}%
\contentsline {subsubsection}{بلوک اول (\lr {\lr {W-MSA}}):}{51}{section*.39}%
\contentsline {subsubsection}{بلوک دوم (\lr {\lr {SW-MSA}}):}{51}{section*.40}%
\contentsline {subsection}{\numberline {3.11.6}Mlp}{52}{subsection.3.11.6}%
\contentsline {subsection}{\numberline {3.11.7}\lr {patch merging}}{53}{subsection.3.11.7}%
\contentsline {subsubsection}{1. انتخاب بلوک‌های \((2 \times 2)\)}{54}{section*.41}%
\contentsline {subsubsection}{2. ادغام (Concat) ویژگی‌های چهار پیکسل}{54}{section*.42}%
\contentsline {subsubsection}{3. لایهٔ خطی برای تغییر بعد}{54}{section*.43}%
\contentsline {subsubsection}{4. کاهش ابعاد مکانی}{54}{section*.44}%
\contentsline {chapter}{\numberline {4}پیشینه پژوهش}{57}{chapter.4}%
\contentsline {subsection}{\numberline {4.0.1}ویژگی‌های محلی (\lr {Local Features})}{58}{subsection.4.0.1}%
\contentsline {subsection}{\numberline {4.0.2}ویژگی‌های جهانی (\lr {Global Features})}{58}{subsection.4.0.2}%
\contentsline {subsection}{\numberline {4.0.3}ترانسفورمرها و محدودیت‌های دید محلی}{59}{subsection.4.0.3}%
\contentsline {subsection}{\numberline {4.0.4}روش اول:}{59}{subsection.4.0.4}%
\contentsline {subsection}{\numberline {4.0.5}تبدیل تصاویر به دو پچ مجزا:}{59}{subsection.4.0.5}%
\contentsline {subsection}{\numberline {4.0.6}هماهنگ سازی پچ ها:}{60}{subsection.4.0.6}%
\contentsline {subsection}{\numberline {4.0.7}\lr {Positional Embedding}}{64}{subsection.4.0.7}%
\contentsline {subsection}{\numberline {4.0.8}لایه های اول تا هشتم انکودر}{65}{subsection.4.0.8}%
\contentsline {subsection}{\numberline {4.0.9}لایه نهم انکودر}{65}{subsection.4.0.9}%
\contentsline {subsection}{\numberline {4.0.10}محاسبهٔ ماتریس شباهت (\(QK^T\)) و میانگین‌گیری}{66}{subsection.4.0.10}%
\contentsline {subsection}{\numberline {4.0.11}اعمال مقیاس‌بندی \( \frac {1}{\sqrt {d_k}} \) و \textit {Softmax}}{67}{subsection.4.0.11}%
\contentsline {subsection}{\numberline {4.0.12}ادغام وزنی}{69}{subsection.4.0.12}%
\contentsline {section}{\numberline {4.1}روش دوم down sampling: }{69}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}حرکت تدریجی از جزئیات به کلیت}{71}{subsection.4.1.1}%
\contentsline {subsection}{\numberline {4.1.2}کم نشدن پارامتر ها در این مدل}{72}{subsection.4.1.2}%
\contentsline {paragraph}{لایه‌های تعبیه‌ساز و موقعیتی (Positional Embedding)}{72}{section*.57}%
\contentsline {paragraph}{توجه چندسری (Multi-Head Attention)}{72}{section*.58}%
\contentsline {paragraph}{شبکه‌های MLP داخل هر بلوک ترنسفورمر}{72}{section*.59}%
\contentsline {chapter}{\numberline {5}آزمایشات و نتایج}{74}{chapter.5}%
\contentsline {chapter}{کتاب‌نامه}{75}{chapter*.60}%
\contentsline {chapter}{\numberline {آ}جزئیات مدل‌ها و جدول پارامترها}{80}{appendix.Alph1}%
